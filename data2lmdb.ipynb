{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d46192",
   "metadata": {},
   "source": [
    "### Script for Converting Datasets into LMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ed152",
   "metadata": {},
   "source": [
    "Use this notebook as an example of saving the data with lmdb format.\n",
    "We use this format to store/load large scale datasets such as ImageNetMini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a1288-7638-477e-b6c6-2a712a9c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import lmdb\n",
    "import os\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f7c12-d293-4867-96a7-4f0dfe3f900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loads_data(buf):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        buf: the output of `dumps`.\n",
    "    \"\"\"\n",
    "    return pickle.loads(buf)\n",
    "\n",
    "def dumps_data(obj):\n",
    "    \"\"\"\n",
    "    Serialize an object.\n",
    "    Returns:\n",
    "        Implementation-dependent bytes-like object\n",
    "    \"\"\"\n",
    "    return pickle.dumps(obj)\n",
    "\n",
    "def datasetImageNet(root='./data', train=True, transform=None):\n",
    "    if train: root = os.path.join(root, 'ILSVRC2012_img_train')\n",
    "    else: root = os.path.join(root, 'ILSVRC2012_img_val')\n",
    "    return torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
    "\n",
    "\n",
    "def datasetImageNetMini(root='./data', train=True, transform=None):\n",
    "    dataset = datasetImageNet(root=root, train=train, transform=transform)\n",
    "    ''' imagenet-mini is a subset of the first 100 classes of ImageNet '''\n",
    "    idx             = np.where( np.array(dataset.targets) < 100)[0]\n",
    "    dataset.samples = [ dataset.samples[ii] for ii in idx ]\n",
    "    dataset.targets = [ dataset.targets[ii] for ii in idx ]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488374b-c412-4839-abd3-d2c24494fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "base_size       = 256\n",
    "\n",
    "train_transform = [transforms.Resize([base_size, base_size]),]\n",
    "test_transform  = [transforms.Resize(base_size),\n",
    "                   transforms.CenterCrop(base_size),]\n",
    "\n",
    "train_transform = transforms.Compose(train_transform)\n",
    "test_transform  = transforms.Compose(test_transform)\n",
    "train_dataset   = datasetImageNetMini(root='/ImageNet_2012_PATH/', train=True, transform=train_transform)\n",
    "test_dataset    = datasetImageNetMini(root='/ImageNet_2012_PATH/', train=False, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b027089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data    = np.zeros_like(noise, dtype=np.int16)\n",
    "targets = [] \n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    data[i] = np.asarray(train_dataset[i][0], dtype=np.int16)\n",
    "    targets.append(train_dataset[i][1])\n",
    "    \n",
    "    if i%5000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc7aa0-4b57-4338-aa5a-b2e4a3f69daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name            = 'CLEAN'\n",
    "write_frequency = 5000\n",
    "\n",
    "lmdb_path = os.path.join('./data/', \"%s.lmdb\" % name)\n",
    "isdir     = os.path.isdir(lmdb_path)\n",
    "\n",
    "print(\"Generate LMDB to %s\" % lmdb_path)\n",
    "\n",
    "db = lmdb.open(lmdb_path, subdir=isdir,\n",
    "               map_size=1099511627776 * 2, readonly=False,\n",
    "               meminit=False, map_async=True)\n",
    "\n",
    "txn = db.begin(write=True)\n",
    "\n",
    "for idx in range(data.shape[0]):\n",
    "    \n",
    "    image  = Image.fromarray(np.uint8(data[idx]))\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"png\", quality=100)\n",
    "    val   = buffer.getvalue()\n",
    "    label = targets[idx]\n",
    "\n",
    "    # Create a tuple of image and label\n",
    "    imglabel_tuple = (val, label)\n",
    "\n",
    "    txn.put(u'{}'.format(idx).encode('ascii'), dumps_data(imglabel_tuple))\n",
    "    \n",
    "    if idx % write_frequency == 0:\n",
    "        print(\"[%d/%d]\" % (idx, data.shape[0]))\n",
    "        txn.commit()\n",
    "        txn = db.begin(write=True)\n",
    "\n",
    "# finish iterating through dataset\n",
    "txn.commit()\n",
    "keys = [u'{}'.format(k).encode('ascii') for k in range(idx + 1)]\n",
    "with db.begin(write=True) as txn:\n",
    "    txn.put(b'__keys__', dumps_data(keys))\n",
    "    txn.put(b'__len__', dumps_data(len(keys)))\n",
    "\n",
    "print(\"Flushing database ...\")\n",
    "db.sync()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 14:32:16) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ca7213c096e28ea3f994b8403b2ef8ae1c38ee8c6683cb8c57876756f5e5759"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
